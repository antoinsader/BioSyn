{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "max_length = 25\n",
    "topk = 20\n",
    "use_cuda = torch.cuda.is_available()\n",
    "learning_rate = .0001\n",
    "weight_decay = 0.01\n",
    "\n",
    "train_batch_size = 128\n",
    "\n",
    "use_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "root = \"..\"\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "print(sys.path)\n",
    "\n",
    "from src.biosyn import (\n",
    "    QueryDataset, \n",
    "    CandidateDataset, \n",
    "    DictionaryDataset,\n",
    "    TextPreprocess, \n",
    "    RerankNet, \n",
    "    BioSyn\n",
    ")\n",
    "\n",
    "model_name_path= 'dmis-lab/biobert-base-cased-v1.1'\n",
    "train_dictionary_path =  f\"{root}/datasets/ncbi-disease/train_dictionary.txt\"\n",
    "train_dir =  f\"{root}/datasets/ncbi-disease/traindev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def init_seed(seed=None):\n",
    "    if seed is None:\n",
    "        seed = int(round(time.time() * 1000)) % 10000\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def load_dictionary(dictionary_path):\n",
    "    \"\"\"\n",
    "    load dictionary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary_path : str\n",
    "        a path of dictionary\n",
    "    \"\"\"\n",
    "    dictionary = DictionaryDataset(\n",
    "            dictionary_path = dictionary_path\n",
    "    )\n",
    "    \n",
    "    return dictionary.data\n",
    "    \n",
    "def load_queries(data_dir, filter_composite, filter_duplicate, filter_cuiless):\n",
    "    \"\"\"\n",
    "    load query data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    is_train : bool\n",
    "        train or dev\n",
    "    filter_composite : bool\n",
    "        filter composite mentions\n",
    "    filter_duplicate : bool\n",
    "        filter duplicate queries\n",
    "    filter_cuiless : bool\n",
    "        filter samples with cuiless\n",
    "    \"\"\"\n",
    "    dataset = QueryDataset(\n",
    "        data_dir=data_dir,\n",
    "        filter_composite=filter_composite,\n",
    "        filter_duplicate=filter_duplicate,\n",
    "        filter_cuiless=filter_cuiless\n",
    "    )\n",
    "    \n",
    "    return dataset.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dictionary = load_dictionary(dictionary_path=train_dictionary_path)\n",
    "train_queries = load_queries(\n",
    "    data_dir = train_dir, \n",
    "    filter_composite=True,\n",
    "    filter_duplicate=True,\n",
    "    filter_cuiless=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosyn = BioSyn(\n",
    "        max_length=max_length,\n",
    "        use_cuda=use_cuda,\n",
    "    )\n",
    "biosyn.load_dense_encoder(\n",
    "        model_name_or_path=model_name_path\n",
    "    )\n",
    "model = RerankNet(\n",
    "        learning_rate=learning_rate, \n",
    "        weight_decay=weight_decay,\n",
    "        encoder = biosyn.get_dense_encoder(),\n",
    "        use_cuda=use_cuda\n",
    "    )\n",
    "11==11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CandidateDataset(\n",
    "    queries = train_queries, \n",
    "    dicts = train_dictionary, \n",
    "    tokenizer = biosyn.tokenizer, \n",
    "    topk = topk\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_in_train_dictionary = train_dictionary[:,0]\n",
    "names_in_train_queries = train_queries[:,0]\n",
    "\n",
    "\n",
    "train_query_dense_embeds = biosyn.embed_dense(names=names_in_train_queries, show_progress=True)\n",
    "train_dict_dense_embeds = biosyn.embed_dense(names=names_in_train_dictionary, show_progress=True)\n",
    "train_dense_score_matrix = biosyn.get_score_matrix(\n",
    "    query_embeds=train_query_dense_embeds, \n",
    "    dict_embeds=train_dict_dense_embeds\n",
    ")\n",
    "train_dense_candidate_idxs = biosyn.retrieve_candidate(\n",
    "    score_matrix=train_dense_score_matrix, \n",
    "    topk=topk\n",
    ")\n",
    "train_dense_candidate_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosyn.embed_and_build_faiss(batch_size=4096)\n",
    "cand_idxs = biosyn.embed_queries_with_search(batch_size=4096)\n",
    "cand_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dense_candidate_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_idxs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
